For small datasets. If the model is fast to run, it's probably worth switching to cross-validation.
Use a pipeline for cross-validation. 
We define below a function get_score with argument n_estimators for the RF model

from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.model_selection import cross_val_score

def get_score(n_estimators):
    
    my_pipeline = Pipeline(steps=[('preprocessor', SimpleImputer()),   
                              ('model', RandomForestRegressor(n_estimators,random_state=0))
                             ])

    scores = -1 * cross_val_score(my_pipeline, X, y,      # Multiply by -1 since sklearn calculates *negative* MAE
                              cv=3,
                              scoring='neg_mean_absolute_error')

    return scores.mean()  #We want to have only one score so we take the mean of the K-scores
    
    
# Tune hyperparam using cross-validation
results = {}   #create a dictionary with the different results
n_estimators_range = list(range(50,450,50))   # for n_estimators = 50, 100, 150,... 400.
for i in n_estimators_range:
    results[i] = get_score(i) 
    
# Plot the results
import matplotlib.pyplot as plt
%matplotlib inline

plt.plot(list(results.keys()), list(results.values()))
plt.show()
